{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c44bc49",
   "metadata": {
    "papermill": {
     "duration": 0.011992,
     "end_time": "2021-08-03T16:24:26.139638",
     "exception": false,
     "start_time": "2021-08-03T16:24:26.127646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "感谢大佬[h053473666](https://www.kaggle.com/h053473666)的数据集[https://www.kaggle.com/h053473666/siimcovid19-512-img-png-600-study-png](https://www.kaggle.com/h053473666/siimcovid19-512-img-png-600-study-png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d84d03c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:26.187215Z",
     "iopub.status.busy": "2021-08-03T16:24:26.174334Z",
     "iopub.status.idle": "2021-08-03T16:24:36.163007Z",
     "shell.execute_reply": "2021-08-03T16:24:36.163518Z",
     "shell.execute_reply.started": "2021-06-25T01:50:56.652214Z"
    },
    "papermill": {
     "duration": 10.012802,
     "end_time": "2021-08-03T16:24:36.163847",
     "exception": false,
     "start_time": "2021-08-03T16:24:26.151045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54eb319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:36.190771Z",
     "iopub.status.busy": "2021-08-03T16:24:36.189723Z",
     "iopub.status.idle": "2021-08-03T16:24:43.620717Z",
     "shell.execute_reply": "2021-08-03T16:24:43.622017Z",
     "shell.execute_reply.started": "2021-06-25T01:51:05.450778Z"
    },
    "papermill": {
     "duration": 7.44685,
     "end_time": "2021-08-03T16:24:43.622222",
     "exception": false,
     "start_time": "2021-08-03T16:24:36.175372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7411a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:43.654302Z",
     "iopub.status.busy": "2021-08-03T16:24:43.653476Z",
     "iopub.status.idle": "2021-08-03T16:24:43.657697Z",
     "shell.execute_reply": "2021-08-03T16:24:43.657176Z",
     "shell.execute_reply.started": "2021-06-25T01:51:12.448002Z"
    },
    "papermill": {
     "duration": 0.023576,
     "end_time": "2021-08-03T16:24:43.657862",
     "exception": false,
     "start_time": "2021-08-03T16:24:43.634286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIIM_parameters: {'SEED': 0, 'FOLDS': 5, 'BATCH_SIZES': 18, 'EPOCHS': 40, 'IMAGE_SIZE': 512}\n"
     ]
    }
   ],
   "source": [
    "SEED = 0        #随机数种子，用来KFold分数据集\n",
    "FOLDS = 5        #交叉验证次数\n",
    "BATCH_SIZES = 18\n",
    "EPOCHS = 40\n",
    "ls = 0.015       # 标签平滑，可以尝试0.015，不用请写0，可抗过拟合\n",
    "IMAGE_SIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n",
    "\n",
    "SIIM_para = {}\n",
    "SIIM_para['SEED'] = SEED\n",
    "SIIM_para['FOLDS'] = FOLDS\n",
    "SIIM_para['BATCH_SIZES'] = BATCH_SIZES\n",
    "SIIM_para['EPOCHS'] = EPOCHS\n",
    "SIIM_para['IMAGE_SIZE'] = IMAGE_SIZE[8]\n",
    "print('SIIM_parameters: {}'.format(SIIM_para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbd7ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:43.690787Z",
     "iopub.status.busy": "2021-08-03T16:24:43.690001Z",
     "iopub.status.idle": "2021-08-03T16:24:43.693996Z",
     "shell.execute_reply": "2021-08-03T16:24:43.693198Z",
     "shell.execute_reply.started": "2021-06-25T01:51:12.457808Z"
    },
    "papermill": {
     "duration": 0.024538,
     "end_time": "2021-08-03T16:24:43.694165",
     "exception": false,
     "start_time": "2021-08-03T16:24:43.669627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback():\n",
    "    lr_start   = 1e-4 # 初始学习率\n",
    "    lr_max   =  2e-4# 最大学习率\n",
    "    lr_min     = 1e-7 #最小学习率\n",
    "    lr_ramp_ep =  3 # 用几个epoch达到最大学习率\n",
    "    lr_sus_ep  =  3# 用最大的学习率跑几个epoch\n",
    "    lr_decay   = .4 # 退火，常用方法\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0627c03e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:43.726661Z",
     "iopub.status.busy": "2021-08-03T16:24:43.725946Z",
     "iopub.status.idle": "2021-08-03T16:24:43.729661Z",
     "shell.execute_reply": "2021-08-03T16:24:43.729013Z",
     "shell.execute_reply.started": "2021-06-25T01:51:12.468878Z"
    },
    "papermill": {
     "duration": 0.022352,
     "end_time": "2021-08-03T16:24:43.729839",
     "exception": false,
     "start_time": "2021-08-03T16:24:43.707487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def auto_select_strategy():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    \n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95e83af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:43.768974Z",
     "iopub.status.busy": "2021-08-03T16:24:43.757979Z",
     "iopub.status.idle": "2021-08-03T16:24:43.776693Z",
     "shell.execute_reply": "2021-08-03T16:24:43.776155Z",
     "shell.execute_reply.started": "2021-06-25T01:51:12.480716Z"
    },
    "papermill": {
     "duration": 0.034771,
     "end_time": "2021-08-03T16:24:43.776875",
     "exception": false,
     "start_time": "2021-08-03T16:24:43.742104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):\n",
    "    def decode(path):\n",
    "        file_bytes = tf.io.read_file(path)\n",
    "\n",
    "        if ext == 'png':\n",
    "            img = tf.image.decode_png(file_bytes, channels=3)\n",
    "        elif ext in ['jpg', 'jpeg']:\n",
    "            img = tf.image.decode_jpeg(file_bytes, channels=3)\n",
    "        else:\n",
    "            raise ValueError(\"Image extension not supported\")\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.image.resize(img, target_size)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "        return decode(path), label\n",
    "    \n",
    "    return decode_with_labels if with_labels else decode\n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True):\n",
    "    def augment(img):\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img = tf.image.flip_left_right(img)\n",
    "    \n",
    "        if tf.random.uniform(()) > 0.4:\n",
    "            img = tf.image.flip_up_down(img)\n",
    "\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img = tf.image.rot90(img, k=1)\n",
    "\n",
    "#        if tf.random.uniform(()) > 0.45:\n",
    "#            img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "\n",
    "#        if tf.random.uniform(()) > 0.45:\n",
    "#            img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "#            \n",
    "#        if tf.random.uniform(()) > 0.45:\n",
    "#            img = tf.image.random_brightness(img, 0.1)\n",
    "        return img\n",
    "    \n",
    "    def augment_with_labels(img, label):\n",
    "        return augment(img), label\n",
    "    \n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "def build_dataset(paths, labels=None, bsize=128, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=True, shuffle=1024, \n",
    "                  cache_dir=\"\"):\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "    \n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "    \n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "    \n",
    "    dset = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    dset = dset.cache(cache_dir) if cache else dset\n",
    "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset\n",
    "    dset = dset.batch(bsize).prefetch(AUTO)\n",
    "    \n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e7460db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:43.876959Z",
     "iopub.status.busy": "2021-08-03T16:24:43.824948Z",
     "iopub.status.idle": "2021-08-03T16:24:50.186930Z",
     "shell.execute_reply": "2021-08-03T16:24:50.187962Z",
     "shell.execute_reply.started": "2021-06-25T01:51:12.499541Z"
    },
    "papermill": {
     "duration": 6.399039,
     "end_time": "2021-08-03T16:24:50.188158",
     "exception": false,
     "start_time": "2021-08-03T16:24:43.789119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU: grpc://10.0.0.2:8470\n",
      "Running on 8 replicas\n"
     ]
    }
   ],
   "source": [
    "COMPETITION_NAME = \"siimcovid19-512-img-png-600-study-png\"\n",
    "strategy = auto_select_strategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync * BATCH_SIZES\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6aca44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:50.219153Z",
     "iopub.status.busy": "2021-08-03T16:24:50.218410Z",
     "iopub.status.idle": "2021-08-03T16:24:50.297880Z",
     "shell.execute_reply": "2021-08-03T16:24:50.298403Z",
     "shell.execute_reply.started": "2021-06-25T01:51:18.785363Z"
    },
    "papermill": {
     "duration": 0.097164,
     "end_time": "2021-08-03T16:24:50.298608",
     "exception": false,
     "start_time": "2021-08-03T16:24:50.201444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n",
    "df = pd.read_csv('../input/siimcov19csv/train.csv')\n",
    "label_cols = df.columns[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dccb1e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:50.333674Z",
     "iopub.status.busy": "2021-08-03T16:24:50.332677Z",
     "iopub.status.idle": "2021-08-03T16:24:50.336152Z",
     "shell.execute_reply": "2021-08-03T16:24:50.335516Z",
     "shell.execute_reply.started": "2021-06-25T01:51:18.86669Z"
    },
    "papermill": {
     "duration": 0.024472,
     "end_time": "2021-08-03T16:24:50.336300",
     "exception": false,
     "start_time": "2021-08-03T16:24:50.311828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(dim=512):\n",
    "    \n",
    "    inp = tf.keras.layers.Input(shape=(dim,dim,3))\n",
    "    base = tf.keras.applications.InceptionResNetV2(input_shape=(dim,dim,3),weights='imagenet',include_top=False)\n",
    "\n",
    "    x = base(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inp,outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=ls) \n",
    "    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "934e0ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:50.371049Z",
     "iopub.status.busy": "2021-08-03T16:24:50.370333Z",
     "iopub.status.idle": "2021-08-03T16:24:50.381657Z",
     "shell.execute_reply": "2021-08-03T16:24:50.382159Z",
     "shell.execute_reply.started": "2021-06-25T01:51:18.880637Z"
    },
    "papermill": {
     "duration": 0.033522,
     "end_time": "2021-08-03T16:24:50.382358",
     "exception": false,
     "start_time": "2021-08-03T16:24:50.348836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n",
    "df['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, groups = df.StudyInstanceUID.tolist())):\n",
    "    df.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1242aaaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:24:50.410219Z",
     "iopub.status.busy": "2021-08-03T16:24:50.409520Z",
     "iopub.status.idle": "2021-08-03T17:59:00.047307Z",
     "shell.execute_reply": "2021-08-03T17:59:00.048289Z"
    },
    "papermill": {
     "duration": 5649.654017,
     "end_time": "2021-08-03T17:59:00.048621",
     "exception": true,
     "start_time": "2021-08-03T16:24:50.394604",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 14, 14, 1536)      54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 55,911,649\n",
      "Trainable params: 55,851,105\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 357s 5s/step - loss: 0.5900 - auc: 0.6768 - val_loss: 1.0256 - val_auc: 0.7093\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.5082 - auc: 0.8097 - val_loss: 0.5081 - val_auc: 0.8285\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.4570 - auc: 0.8421 - val_loss: 0.4770 - val_auc: 0.8243\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.4197 - auc: 0.8746 - val_loss: 0.5150 - val_auc: 0.8081\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.4196 - auc: 0.8761 - val_loss: 0.5241 - val_auc: 0.8450\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 25s 708ms/step - loss: 0.3847 - auc: 0.9000 - val_loss: 0.5811 - val_auc: 0.8177\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.3717 - auc: 0.9058 - val_loss: 0.6120 - val_auc: 0.8200\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.3415 - auc: 0.9245 - val_loss: 0.4646 - val_auc: 0.8346\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2825 - auc: 0.9506 - val_loss: 0.4924 - val_auc: 0.8390\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 24s 701ms/step - loss: 0.2434 - auc: 0.9655 - val_loss: 0.4832 - val_auc: 0.8416\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2351 - auc: 0.9670 - val_loss: 0.4815 - val_auc: 0.8481\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2365 - auc: 0.9671 - val_loss: 0.4811 - val_auc: 0.8513\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.2166 - auc: 0.9748 - val_loss: 0.4807 - val_auc: 0.8540\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 25s 703ms/step - loss: 0.2262 - auc: 0.9699 - val_loss: 0.4817 - val_auc: 0.8546\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2201 - auc: 0.9743 - val_loss: 0.4845 - val_auc: 0.8546\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2073 - auc: 0.9770 - val_loss: 0.4847 - val_auc: 0.8552\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2290 - auc: 0.9704 - val_loss: 0.4816 - val_auc: 0.8575\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2215 - auc: 0.9723 - val_loss: 0.4813 - val_auc: 0.8578\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2165 - auc: 0.9727 - val_loss: 0.4796 - val_auc: 0.8590\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2279 - auc: 0.9706 - val_loss: 0.4779 - val_auc: 0.8607\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2067 - auc: 0.9774 - val_loss: 0.4748 - val_auc: 0.8623\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.2001 - auc: 0.9795 - val_loss: 0.4743 - val_auc: 0.8630\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.2270 - auc: 0.9691 - val_loss: 0.4727 - val_auc: 0.8640\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2182 - auc: 0.9724 - val_loss: 0.4727 - val_auc: 0.8644\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.2229 - auc: 0.9720 - val_loss: 0.4723 - val_auc: 0.8644\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2131 - auc: 0.9752 - val_loss: 0.4719 - val_auc: 0.8648\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2106 - auc: 0.9767 - val_loss: 0.4709 - val_auc: 0.8655\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 24s 690ms/step - loss: 0.2034 - auc: 0.9772 - val_loss: 0.4716 - val_auc: 0.8652\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2094 - auc: 0.9765 - val_loss: 0.4715 - val_auc: 0.8654\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2151 - auc: 0.9747 - val_loss: 0.4714 - val_auc: 0.8655\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 25s 706ms/step - loss: 0.2186 - auc: 0.9728 - val_loss: 0.4722 - val_auc: 0.8653\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2219 - auc: 0.9706 - val_loss: 0.4716 - val_auc: 0.8657\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 25s 726ms/step - loss: 0.1990 - auc: 0.9788 - val_loss: 0.4711 - val_auc: 0.8657\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 25s 705ms/step - loss: 0.2159 - auc: 0.9736 - val_loss: 0.4722 - val_auc: 0.8654\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 24s 702ms/step - loss: 0.2108 - auc: 0.9766 - val_loss: 0.4722 - val_auc: 0.8657\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2146 - auc: 0.9753 - val_loss: 0.4720 - val_auc: 0.8658\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.2163 - auc: 0.9730 - val_loss: 0.4715 - val_auc: 0.8657\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2211 - auc: 0.9717 - val_loss: 0.4723 - val_auc: 0.8658\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.2080 - auc: 0.9764 - val_loss: 0.4723 - val_auc: 0.8656\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 25s 702ms/step - loss: 0.2217 - auc: 0.9731 - val_loss: 0.4715 - val_auc: 0.8660\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 14, 14, 1536)      54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 55,911,649\n",
      "Trainable params: 55,851,105\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 311s 4s/step - loss: 0.5818 - auc: 0.6829 - val_loss: 0.7444 - val_auc: 0.7703\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.4891 - auc: 0.8200 - val_loss: 0.5817 - val_auc: 0.7945\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 25s 702ms/step - loss: 0.4419 - auc: 0.8594 - val_loss: 0.6427 - val_auc: 0.7981\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.4404 - auc: 0.8607 - val_loss: 0.6612 - val_auc: 0.8009\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.4224 - auc: 0.8784 - val_loss: 0.6368 - val_auc: 0.8123\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.3886 - auc: 0.8983 - val_loss: 0.4689 - val_auc: 0.8353\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 25s 705ms/step - loss: 0.3923 - auc: 0.8963 - val_loss: 0.6048 - val_auc: 0.7997\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.3233 - auc: 0.9349 - val_loss: 0.7433 - val_auc: 0.8012\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.2861 - auc: 0.9492 - val_loss: 0.5718 - val_auc: 0.8152\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.2432 - auc: 0.9662 - val_loss: 0.6178 - val_auc: 0.8110\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2133 - auc: 0.9770 - val_loss: 0.5845 - val_auc: 0.8179\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 24s 690ms/step - loss: 0.2186 - auc: 0.9729 - val_loss: 0.5721 - val_auc: 0.8215\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2232 - auc: 0.9711 - val_loss: 0.5606 - val_auc: 0.8231\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2227 - auc: 0.9727 - val_loss: 0.5556 - val_auc: 0.8239\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2020 - auc: 0.9784 - val_loss: 0.5554 - val_auc: 0.8237\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 25s 703ms/step - loss: 0.2222 - auc: 0.9729 - val_loss: 0.5558 - val_auc: 0.8224\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2325 - auc: 0.9685 - val_loss: 0.5598 - val_auc: 0.8217\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2146 - auc: 0.9746 - val_loss: 0.5573 - val_auc: 0.8223\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.2147 - auc: 0.9750 - val_loss: 0.5576 - val_auc: 0.8221\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2103 - auc: 0.9757 - val_loss: 0.5589 - val_auc: 0.8224\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2142 - auc: 0.9745 - val_loss: 0.5615 - val_auc: 0.8218\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 25s 702ms/step - loss: 0.2025 - auc: 0.9773 - val_loss: 0.5640 - val_auc: 0.8213\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2105 - auc: 0.9754 - val_loss: 0.5672 - val_auc: 0.8198\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.2201 - auc: 0.9727 - val_loss: 0.5672 - val_auc: 0.8205\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.1946 - auc: 0.9808 - val_loss: 0.5683 - val_auc: 0.8203\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2148 - auc: 0.9739 - val_loss: 0.5685 - val_auc: 0.8196\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2161 - auc: 0.9736 - val_loss: 0.5698 - val_auc: 0.8183\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.2100 - auc: 0.9745 - val_loss: 0.5701 - val_auc: 0.8188\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.2217 - auc: 0.9716 - val_loss: 0.5708 - val_auc: 0.8189\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2065 - auc: 0.9773 - val_loss: 0.5719 - val_auc: 0.8185\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2075 - auc: 0.9762 - val_loss: 0.5722 - val_auc: 0.8183\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 25s 708ms/step - loss: 0.2152 - auc: 0.9751 - val_loss: 0.5714 - val_auc: 0.8182\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2206 - auc: 0.9730 - val_loss: 0.5710 - val_auc: 0.8190\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2199 - auc: 0.9725 - val_loss: 0.5704 - val_auc: 0.8189\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2134 - auc: 0.9743 - val_loss: 0.5716 - val_auc: 0.8188\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2055 - auc: 0.9772 - val_loss: 0.5717 - val_auc: 0.8186\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 25s 704ms/step - loss: 0.2011 - auc: 0.9787 - val_loss: 0.5729 - val_auc: 0.8177\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.1969 - auc: 0.9804 - val_loss: 0.5725 - val_auc: 0.8186\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.1982 - auc: 0.9796 - val_loss: 0.5721 - val_auc: 0.8184\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 24s 689ms/step - loss: 0.2074 - auc: 0.9768 - val_loss: 0.5727 - val_auc: 0.8185\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 14, 14, 1536)      54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 55,911,649\n",
      "Trainable params: 55,851,105\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 313s 4s/step - loss: 0.5790 - auc: 0.6772 - val_loss: 0.9390 - val_auc: 0.7106\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.4812 - auc: 0.8282 - val_loss: 0.9132 - val_auc: 0.8131\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 25s 701ms/step - loss: 0.4438 - auc: 0.8594 - val_loss: 1.0617 - val_auc: 0.8346\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.4254 - auc: 0.8713 - val_loss: 0.5208 - val_auc: 0.8253\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 25s 707ms/step - loss: 0.4103 - auc: 0.8818 - val_loss: 0.5363 - val_auc: 0.7979\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 24s 701ms/step - loss: 0.3969 - auc: 0.8899 - val_loss: 0.6283 - val_auc: 0.8408\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 25s 703ms/step - loss: 0.3603 - auc: 0.9130 - val_loss: 0.5336 - val_auc: 0.8134\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.3244 - auc: 0.9302 - val_loss: 0.6832 - val_auc: 0.8273\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 24s 690ms/step - loss: 0.2621 - auc: 0.9582 - val_loss: 0.5175 - val_auc: 0.8507\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2327 - auc: 0.9685 - val_loss: 0.5311 - val_auc: 0.8433\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2136 - auc: 0.9746 - val_loss: 0.5521 - val_auc: 0.8416\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2155 - auc: 0.9733 - val_loss: 0.5511 - val_auc: 0.8405\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2000 - auc: 0.9792 - val_loss: 0.5493 - val_auc: 0.8407\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2024 - auc: 0.9781 - val_loss: 0.5484 - val_auc: 0.8410\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.1980 - auc: 0.9802 - val_loss: 0.5493 - val_auc: 0.8402\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2189 - auc: 0.9741 - val_loss: 0.5479 - val_auc: 0.8397\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 25s 703ms/step - loss: 0.2091 - auc: 0.9758 - val_loss: 0.5473 - val_auc: 0.8401\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.2061 - auc: 0.9772 - val_loss: 0.5450 - val_auc: 0.8406\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 25s 701ms/step - loss: 0.2085 - auc: 0.9774 - val_loss: 0.5434 - val_auc: 0.8416\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.2226 - auc: 0.9706 - val_loss: 0.5440 - val_auc: 0.8400\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2022 - auc: 0.9786 - val_loss: 0.5458 - val_auc: 0.8395\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2197 - auc: 0.9720 - val_loss: 0.5463 - val_auc: 0.8389\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2048 - auc: 0.9763 - val_loss: 0.5445 - val_auc: 0.8394\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2132 - auc: 0.9750 - val_loss: 0.5446 - val_auc: 0.8396\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.1932 - auc: 0.9812 - val_loss: 0.5454 - val_auc: 0.8393\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2038 - auc: 0.9767 - val_loss: 0.5454 - val_auc: 0.8393\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 24s 691ms/step - loss: 0.2009 - auc: 0.9779 - val_loss: 0.5432 - val_auc: 0.8400\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 25s 703ms/step - loss: 0.2120 - auc: 0.9753 - val_loss: 0.5428 - val_auc: 0.8406\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.1964 - auc: 0.9794 - val_loss: 0.5450 - val_auc: 0.8397\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.1970 - auc: 0.9803 - val_loss: 0.5454 - val_auc: 0.8398\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 24s 701ms/step - loss: 0.2037 - auc: 0.9775 - val_loss: 0.5440 - val_auc: 0.8402\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 24s 701ms/step - loss: 0.2216 - auc: 0.9720 - val_loss: 0.5431 - val_auc: 0.8406\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.2005 - auc: 0.9780 - val_loss: 0.5454 - val_auc: 0.8398\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2048 - auc: 0.9765 - val_loss: 0.5466 - val_auc: 0.8390\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2023 - auc: 0.9788 - val_loss: 0.5468 - val_auc: 0.8393\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2199 - auc: 0.9731 - val_loss: 0.5493 - val_auc: 0.8384\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2151 - auc: 0.9752 - val_loss: 0.5460 - val_auc: 0.8399\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2096 - auc: 0.9757 - val_loss: 0.5471 - val_auc: 0.8394\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2064 - auc: 0.9758 - val_loss: 0.5460 - val_auc: 0.8399\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 26s 757ms/step - loss: 0.2066 - auc: 0.9763 - val_loss: 0.5460 - val_auc: 0.8397\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 14, 14, 1536)      54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 55,911,649\n",
      "Trainable params: 55,851,105\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 325s 4s/step - loss: 0.5962 - auc: 0.6743 - val_loss: 0.6974 - val_auc: 0.7329\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.4723 - auc: 0.8366 - val_loss: 0.5613 - val_auc: 0.7720\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.4413 - auc: 0.8585 - val_loss: 0.6569 - val_auc: 0.7984\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.4324 - auc: 0.8658 - val_loss: 0.5148 - val_auc: 0.7995\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.4096 - auc: 0.8845 - val_loss: 0.5315 - val_auc: 0.8229\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.3964 - auc: 0.8876 - val_loss: 0.5709 - val_auc: 0.8191\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.3760 - auc: 0.9059 - val_loss: 0.5628 - val_auc: 0.8213\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.3140 - auc: 0.9378 - val_loss: 0.6601 - val_auc: 0.8165\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2817 - auc: 0.9517 - val_loss: 0.6099 - val_auc: 0.8389\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2397 - auc: 0.9655 - val_loss: 0.5862 - val_auc: 0.8403\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2220 - auc: 0.9713 - val_loss: 0.5686 - val_auc: 0.8458\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.2202 - auc: 0.9728 - val_loss: 0.5595 - val_auc: 0.8473\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2121 - auc: 0.9752 - val_loss: 0.5521 - val_auc: 0.8487\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2087 - auc: 0.9759 - val_loss: 0.5470 - val_auc: 0.8502\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2057 - auc: 0.9770 - val_loss: 0.5425 - val_auc: 0.8513\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.1997 - auc: 0.9783 - val_loss: 0.5390 - val_auc: 0.8516\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 24s 699ms/step - loss: 0.2044 - auc: 0.9769 - val_loss: 0.5382 - val_auc: 0.8519\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2121 - auc: 0.9748 - val_loss: 0.5376 - val_auc: 0.8526\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.2091 - auc: 0.9760 - val_loss: 0.5379 - val_auc: 0.8531\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 25s 705ms/step - loss: 0.2007 - auc: 0.9768 - val_loss: 0.5394 - val_auc: 0.8531\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2070 - auc: 0.9752 - val_loss: 0.5397 - val_auc: 0.8527\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 25s 702ms/step - loss: 0.1969 - auc: 0.9787 - val_loss: 0.5409 - val_auc: 0.8526\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2094 - auc: 0.9750 - val_loss: 0.5405 - val_auc: 0.8525\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2090 - auc: 0.9749 - val_loss: 0.5399 - val_auc: 0.8525\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 24s 701ms/step - loss: 0.2212 - auc: 0.9706 - val_loss: 0.5409 - val_auc: 0.8522\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2082 - auc: 0.9761 - val_loss: 0.5395 - val_auc: 0.8526\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 24s 698ms/step - loss: 0.2130 - auc: 0.9751 - val_loss: 0.5408 - val_auc: 0.8526\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 24s 697ms/step - loss: 0.2194 - auc: 0.9729 - val_loss: 0.5405 - val_auc: 0.8530\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2024 - auc: 0.9787 - val_loss: 0.5420 - val_auc: 0.8520\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 24s 695ms/step - loss: 0.2234 - auc: 0.9708 - val_loss: 0.5415 - val_auc: 0.8522\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 25s 704ms/step - loss: 0.2038 - auc: 0.9774 - val_loss: 0.5427 - val_auc: 0.8522\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 25s 704ms/step - loss: 0.2198 - auc: 0.9727 - val_loss: 0.5424 - val_auc: 0.8521\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2029 - auc: 0.9779 - val_loss: 0.5425 - val_auc: 0.8522\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 25s 702ms/step - loss: 0.2107 - auc: 0.9764 - val_loss: 0.5426 - val_auc: 0.8524\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2039 - auc: 0.9775 - val_loss: 0.5424 - val_auc: 0.8524\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 24s 700ms/step - loss: 0.1946 - auc: 0.9801 - val_loss: 0.5434 - val_auc: 0.8522\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 0.2186 - auc: 0.9730 - val_loss: 0.5429 - val_auc: 0.8524\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 24s 696ms/step - loss: 0.2098 - auc: 0.9755 - val_loss: 0.5427 - val_auc: 0.8526\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 24s 693ms/step - loss: 0.2124 - auc: 0.9733 - val_loss: 0.5431 - val_auc: 0.8524\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 24s 690ms/step - loss: 0.2082 - auc: 0.9758 - val_loss: 0.5434 - val_auc: 0.8521\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 14, 14, 1536)      54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 55,911,649\n",
      "Trainable params: 55,851,105\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "9 root error(s) found.\n  (0) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_3_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_5_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (2) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_4_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (3) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_1_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (4) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (5) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (6) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_2_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[cluster_train_function/_execute_6_0/_3451]]\nHint: If you want to see a list of allocated tensors when OOM ... [truncated]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-839bf9ecc345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_lr_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         validation_data=valid_dataset)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mhist_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1037\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 9 root error(s) found.\n  (0) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_3_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_5_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (2) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_4_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (3) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_1_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (4) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (5) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (6) Resource exhausted: {{function_node __inference_train_function_1123352}} Attempting to reserve 13.16G at the bottom of memory. That was not possible. There are 14.00G free, 0B reserved, and 13.16G reservable.\n\t [[{{node cluster_train_function/_execute_2_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[cluster_train_function/_execute_6_0/_3451]]\nHint: If you want to see a list of allocated tensors when OOM ... [truncated]"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    valid_paths = GCS_DS_PATH + '/image/' + df[df['fold'] == i]['id'] + '.png' #\"/train/\"\n",
    "    train_paths = GCS_DS_PATH + '/image/' + df[df['fold'] != i]['id'] + '.png' #\"/train/\" \n",
    "    valid_labels = df[df['fold'] == i][label_cols].values\n",
    "    train_labels = df[df['fold'] != i][label_cols].values\n",
    "\n",
    "\n",
    "\n",
    "    decoder = build_decoder(with_labels=True, target_size=(IMAGE_SIZE[8], IMAGE_SIZE[8]), ext='png')\n",
    "    test_decoder = build_decoder(with_labels=False, target_size=(IMAGE_SIZE[8], IMAGE_SIZE[8]),ext='png')\n",
    "\n",
    "    train_dataset = build_dataset(\n",
    "        train_paths, train_labels, bsize=REPLICAS, decode_fn=decoder\n",
    "    )\n",
    "\n",
    "    valid_dataset = build_dataset(\n",
    "        valid_paths, valid_labels, bsize=REPLICAS, decode_fn=decoder,\n",
    "        repeat=False, shuffle=False, augment=False\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        n_labels = train_labels.shape[1]\n",
    "    except:\n",
    "        n_labels = 1\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = build_model(dim=IMAGE_SIZE[8])\n",
    "\n",
    "    steps_per_epoch = train_paths.shape[0] // REPLICAS\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'model{i}.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset, \n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint, get_lr_callback()],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_dataset)\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.to_csv(f'history{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5687.859074,
   "end_time": "2021-08-03T17:59:04.858593",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-03T16:24:16.999519",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
