{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f31ec6dc950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "torch.set_printoptions(linewidth=120)\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from focal import FocalLoss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torchvision.transforms as T\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_label = pd.read_csv('../archive/train_study_level.csv')\n",
    "paths = []\n",
    "ids = study_label.id\n",
    "labels = study_label.iloc[:, 1:].to_numpy()\n",
    "for i in range(len(ids)):\n",
    "    paths.append('../archive/study/{x}.png'.format(x = ids[i]))\n",
    "paths = np.array(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6054,), (6054,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.argmax(labels, axis=1)\n",
    "paths.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# for wb data\\ntraining = os.listdir('../train/')\\nstudy_label = pd.read_csv('../archive/train_study_level.csv')\\nimage_label = pd.read_csv('../archive/train_image_level.csv')\\npaths = []\\nlabels = []\\ndct = pd.read_csv('train.csv', index_col=0)\\ndct['image'] = dct.image.apply(lambda x: x[:-4])\\ndct = dct.set_index('study').to_dict()['image']\\nfor index, row in study_label.iterrows():\\n    name = dct[row['id'].replace('_study', '')] + '.png'\\n    if name in training:\\n        paths.append('../train/' + name)\\n        if row['Negative for Pneumonia'] == 1:\\n            labels.append(0)\\n        elif row['Typical Appearance'] == 1:\\n            labels.append(1)\\n        elif row['Indeterminate Appearance'] == 1:\\n            labels.append(2)\\n        elif row['Atypical Appearance'] == 1:\\n            labels.append(3)\\n    else:\\n        print(name)\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# for wb data\n",
    "training = os.listdir('../train/')\n",
    "study_label = pd.read_csv('../archive/train_study_level.csv')\n",
    "image_label = pd.read_csv('../archive/train_image_level.csv')\n",
    "paths = []\n",
    "labels = []\n",
    "dct = pd.read_csv('train.csv', index_col=0)\n",
    "dct['image'] = dct.image.apply(lambda x: x[:-4])\n",
    "dct = dct.set_index('study').to_dict()['image']\n",
    "for index, row in study_label.iterrows():\n",
    "    name = dct[row['id'].replace('_study', '')] + '.png'\n",
    "    if name in training:\n",
    "        paths.append('../train/' + name)\n",
    "        if row['Negative for Pneumonia'] == 1:\n",
    "            labels.append(0)\n",
    "        elif row['Typical Appearance'] == 1:\n",
    "            labels.append(1)\n",
    "        elif row['Indeterminate Appearance'] == 1:\n",
    "            labels.append(2)\n",
    "        elif row['Atypical Appearance'] == 1:\n",
    "            labels.append(3)\n",
    "    else:\n",
    "        print(name)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    2855\n",
       " 0    1676\n",
       " 2    1049\n",
       " 3     474\n",
       " dtype: int64,\n",
       " 6054)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels).value_counts(), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=2)\n",
    "train_idx = np.random.choice(np.arange(6054), size=5000, replace=False)\n",
    "train_path = np.array(paths)[train_idx]\n",
    "test_path = np.array(paths)[[x for x in np.arange(6054) if x not in train_idx]]\n",
    "\n",
    "train_label = np.array(labels)[train_idx]\n",
    "test_label = np.array(labels)[[x for x in np.arange(6054) if x not in train_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4)\n",
    "model = nn.DataParallel(model, device_ids = [3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = T.RandomApply(torch.nn.ModuleList([\n",
    "                T.RandomAffine(\n",
    "                    degrees = (10, 30),\n",
    "                    translate = (0.2, 0.2),\n",
    "                ),\n",
    "                T.RandomRotation(degrees=(0, 50)),\n",
    "                T.RandomHorizontalFlip(p=0.5)  \n",
    "            ]),p = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification(nn.Module):\n",
    "    def __init__(self, paths, labels, size=(512,512), train=False, aug=True):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.example = []\n",
    "        self.size =size\n",
    "        self.train = train\n",
    "        self.aug = aug\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = cv2.imread(path)\n",
    "        R, G, B = cv2.split(img)\n",
    "        output1_R = cv2.equalizeHist(R)\n",
    "        output1_G = cv2.equalizeHist(G)\n",
    "        output1_B = cv2.equalizeHist(B)\n",
    "\n",
    "        img = cv2.merge((output1_R, output1_G, output1_B))\n",
    "        #img = (img - np.mean(img))/np.std(img)\n",
    "        img = img/np.mean(img)\n",
    "        img = cv2.resize(img, self.size)\n",
    "\n",
    "        x = torch.from_numpy(np.array(img)).view((3, self.size[0], self.size[1]))\n",
    "        x = x.float()\n",
    "        y = self.labels[idx]\n",
    "        y = torch.tensor(y)\n",
    "        if self.train:\n",
    "            if self.aug:\n",
    "                x = trans(x)\n",
    "            return x, y\n",
    "        else:\n",
    "            return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_compute_fn(y_preds: torch.Tensor, y_targets: torch.Tensor) -> float:\n",
    "\n",
    "    y_true = y_targets.cpu().numpy()\n",
    "    y_pred = y_preds.cpu().numpy()\n",
    "    return roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovo')\n",
    "\n",
    "def one_hot(labels: torch.Tensor, num_classes: int, dtype: torch.dtype = torch.float, dim: int = 1) -> torch.Tensor:\n",
    "    # if `dim` is bigger, add singleton dim at the end\n",
    "    if labels.ndim < dim + 1:\n",
    "        shape = list(labels.shape) + [1] * (dim + 1 - len(labels.shape))\n",
    "        labels = torch.reshape(labels, shape)\n",
    "\n",
    "    sh = list(labels.shape)\n",
    "\n",
    "    if sh[dim] != 1:\n",
    "        raise AssertionError(\"labels should have a channel with length equal to one.\")\n",
    "\n",
    "    sh[dim] = num_classes\n",
    "\n",
    "    o = torch.zeros(size=sh, dtype=dtype, device=labels.device)\n",
    "    labels = o.scatter_(dim=dim, index=labels.long(), value=1)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,model,train_set,test_set,opts):\n",
    "        self.model = model  # neural net\n",
    "        # device agnostic code snippet\n",
    "        self.device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "        self.epochs = opts['epochs']\n",
    "        if opts['opt'] == 'adam':\n",
    "            self.optimizer = torch.optim.Adam(model.parameters(), opts['lr'], weight_decay=1e-5, amsgrad=True)\n",
    "        else:\n",
    "            self.optimizer = torch.optim.SGD(model.parameters(), opts['lr'], momentum=0.9)\n",
    "        if opts['loss'] == 'focal':\n",
    "            self.criterion = FocalLoss(**{\"alpha\": 0.5, \"gamma\": 2.0, \"reduction\": 'mean'})\n",
    "            self.mix = False\n",
    "        elif opts['loss'] == 'ce':\n",
    "            self.criterion = torch.nn.CrossEntropyLoss() \n",
    "            self.mix = False\n",
    "        else:\n",
    "            self.criterion1 = torch.nn.CrossEntropyLoss() \n",
    "            self.criterion2 = FocalLoss(**{\"alpha\": 0.5, \"gamma\": 2.0, \"reduction\": 'mean'})\n",
    "            self.mix = True\n",
    "            \n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                                        batch_size=opts['batch_size'],\n",
    "                                                        shuffle=True)\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                                       batch_size=opts['batch_size'],\n",
    "                                                       shuffle=False)\n",
    "        #self.tb = SummaryWriter(log_dir='./resruns')\n",
    "        self.best_loss = 1e10\n",
    "        self.tr_loss = []\n",
    "        self.sche = ExponentialLR(self.optimizer, gamma=0.1)\n",
    "        \n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train() #put model in training mode\n",
    "            self.tr_loss = []\n",
    "            for i, (data,labels) in tqdm(enumerate(self.train_loader),\n",
    "                                                   total = len(self.train_loader)):\n",
    "                print(labels)\n",
    "                data, labels = data.to(self.device),labels.to(self.device)\n",
    "                self.optimizer.zero_grad()  \n",
    "                outputs = self.model(data)\n",
    "                if self.mix == False:\n",
    "                    loss = self.criterion(outputs, labels) \n",
    "                    loss.backward()                        \n",
    "                    self.optimizer.step()                  \n",
    "                    self.tr_loss.append(loss.item())   \n",
    "                else:\n",
    "                    loss = self.criterion1(outputs, labels) + self.criterion2(outputs, labels)\n",
    "                    loss.backward()                        \n",
    "                    self.optimizer.step()                  \n",
    "                    self.tr_loss.append(loss.item()) \n",
    "            #self.tb.add_scalar(\"Train Loss\", np.mean(self.tr_loss), epoch)\n",
    "            self.test(epoch) # run through the validation set\n",
    "            self.sche.step()\n",
    "        self.tb.close()\n",
    "            \n",
    "    def test(self,epoch):    \n",
    "        self.model.eval()    # puts model in eval mode - not necessary for this demo but good to know\n",
    "        self.test_loss = []\n",
    "        self.test_accuracy = []\n",
    "        self.predicted = []\n",
    "        self.true = []\n",
    "        for i, (data, labels) in enumerate(self.test_loader):\n",
    "\n",
    "            data, labels = data.to(self.device),labels.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(data)\n",
    "            if self.mix == False:\n",
    "                loss = self.criterion(outputs, labels)\n",
    "            else:\n",
    "                loss = self.criterion1(outputs, labels) + self.criterion2(outputs, labels)\n",
    "            outputs = torch.nn.functional.softmax(outputs, 1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            self.test_loss.append(loss.item())\n",
    "            print(predicted, labels)\n",
    "            self.test_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "            self.predicted.append(predicted)\n",
    "            self.true.append(labels)\n",
    "        \n",
    "        test_auc = roc_auc_compute_fn(one_hot(torch.cat(self.predicted, dim=0), 4), one_hot(torch.cat(self.true, dim=0), 4))\n",
    "\n",
    "        print('epoch: {}, train loss: {}, test loss: {}, test accuracy: {}, test auc: {}'.format( \n",
    "              epoch+1, np.mean(self.tr_loss), np.mean(self.test_loss), np.mean(self.test_accuracy), test_auc))\n",
    "        #self.tb.add_scalar(\"Val Acc\", np.mean(self.test_accuracy), epoch)\n",
    "        #self.tb.add_scalar(\"Val Loss\", np.mean(self.test_loss), epoch)\n",
    "        if np.mean(self.test_loss) < self.best_loss:\n",
    "            self.best_loss = np.mean(self.test_loss)\n",
    "            #torch.save(self.model.state_dict(), './model_weights/resbest.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = classification(train_path[:200], train_label[:200], size=(512, 512), train=True, aug=False)\n",
    "val_set = classification(test_path[:10], train_label[:10], size=(512, 512), train=False, aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25\n",
       "0    16\n",
       "2     7\n",
       "3     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_label[:50]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c8273f5009412e8d10c02aca77433a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 2, 1, 0])\n",
      "tensor([1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1])\n",
      "tensor([1, 2, 1, 3, 2, 0, 0, 0, 1, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0])\n",
      "tensor([0, 1, 0, 1, 3, 1, 0, 1, 1, 0, 1, 1, 0, 0, 2, 0, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 0, 3, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 3, 1, 1])\n",
      "tensor([2, 0, 0, 2, 1, 0, 0, 0, 1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 0, 1])\n",
      "tensor([1, 1, 3, 1, 0, 1, 2, 3, 2, 0, 0, 1, 0, 2, 0, 3, 1, 2, 2, 1])\n",
      "tensor([0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1, 0, 3, 1, 2, 1, 2, 3, 1])\n",
      "tensor([1, 1, 2, 0, 1, 1, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 3, 0, 0, 1, 1, 1, 2, 1, 1, 1])\n",
      "\n",
      "tensor([2, 2, 2, 2, 2, 1, 2, 3, 3, 3], device='cuda:3') tensor([2, 3, 1, 1, 0, 1, 0, 0, 0, 1], device='cuda:3')\n",
      "epoch: 1, train loss: 1.3686195731163024, test loss: 1.398083209991455, test accuracy: 0.2, test auc: 0.5555555555555556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75dfa50f091496da511400e2d0fb457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 1, 2, 2, 1, 1, 0])\n",
      "tensor([1, 1, 2, 1, 0, 3, 1, 0, 0, 1, 1, 1, 0, 3, 2, 1, 0, 1, 1, 1])\n",
      "tensor([1, 2, 0, 1, 0, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 1, 2])\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 0, 1, 1, 1, 3, 1, 1, 1])\n",
      "tensor([0, 2, 1, 2, 0, 1, 0, 1, 1, 0, 2, 3, 3, 1, 1, 1, 2, 1, 0, 1])\n",
      "tensor([2, 1, 1, 0, 1, 3, 0, 0, 0, 1, 3, 1, 1, 0, 1, 0, 1, 0, 1, 1])\n",
      "tensor([1, 0, 2, 1, 0, 1, 1, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 3, 1, 1])\n",
      "tensor([0, 1, 1, 1, 2, 0, 1, 0, 1, 1, 2, 1, 0, 1, 1, 0, 1, 3, 2, 0])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 1, 0, 1, 1, 2, 2, 1, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1])\n",
      "\n",
      "tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 3], device='cuda:3') tensor([2, 3, 1, 1, 0, 1, 0, 0, 0, 1], device='cuda:3')\n",
      "epoch: 2, train loss: 1.3603318214416504, test loss: 1.4008502960205078, test accuracy: 0.2, test auc: 0.5555555555555556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fb0e6db13c4c53b708b9ee943d6104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 2, 2, 1, 2, 0, 2])\n",
      "tensor([1, 0, 1, 0, 1, 1, 2, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([2, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 1, 0, 2, 0, 2, 1, 1, 1, 0])\n",
      "tensor([2, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 2, 0, 2, 0, 3, 1, 1, 1, 1])\n",
      "tensor([3, 3, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, 3])\n",
      "tensor([2, 2, 1, 1, 3, 0, 1, 0, 3, 0, 1, 1, 2, 1, 1, 2, 1, 2, 0, 0])\n",
      "tensor([1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 3, 0, 1, 2, 1])\n",
      "tensor([0, 3, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 3, 0, 1])\n",
      "tensor([0, 0, 0, 0, 1, 2, 1, 3, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
      "\n",
      "tensor([2, 2, 3, 2, 2, 1, 2, 3, 2, 3], device='cuda:3') tensor([2, 3, 1, 1, 0, 1, 0, 0, 0, 1], device='cuda:3')\n",
      "epoch: 3, train loss: 1.347407627105713, test loss: 1.4005681276321411, test accuracy: 0.2, test auc: 0.5555555555555556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80247891bca34132b356c4b5bbcec780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 0, 0, 1, 2])\n",
      "tensor([2, 2, 0, 2, 0, 1, 0, 0, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 2, 2, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 3, 3, 1, 2, 1, 0, 1, 2])\n",
      "tensor([1, 1, 2, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 3, 1, 1, 0, 0, 1, 3, 0, 0, 1, 1])\n",
      "tensor([1, 3, 0, 1, 3, 2, 0, 1, 3, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c6725485044e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-8566fa358051>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xinrui/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xinrui/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xinrui/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xinrui/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xinrui/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Use the max. for normalizing running avg. of gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opts = {\n",
    "    'lr': 1e-5,\n",
    "    'epochs': 50,\n",
    "    'batch_size': 20,\n",
    "    'opt': 'adam',\n",
    "    'loss': 'ce'\n",
    "}\n",
    "train = Trainer(model, train_set, val_set, opts)\n",
    "train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinrui",
   "language": "python",
   "name": "xinrui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
